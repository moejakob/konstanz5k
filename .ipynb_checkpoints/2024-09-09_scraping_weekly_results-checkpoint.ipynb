{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41241e4d-5c0f-4df5-8f9c-ff8ea5a7ab30",
   "metadata": {},
   "source": [
    "# Scraping all runner data from an event\n",
    "This script scrapes the majority of the data. It scrapes all runner data from all runs that have taken place at this event. For the most part it uses the same code as the [the other scraping script](2024-09-08_scraping_5k_KN_history.ipynb), however, there are some adjustments to allow it to scrape a different part of the website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86159578-aaea-49fe-942d-e48cf7b4ef67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import relevant libraries\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pandas as pd\n",
    "import hashlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d364fd-3c8f-4e8d-835c-0833d1f64149",
   "metadata": {},
   "source": [
    "First I use the requests library to scrape the html content of the website. It is important to add a User-Agent header to the method, otherwise the web content will be an error 403 error message.\n",
    "\n",
    "In this case, you need to enter the base url of the event and then the script will access the latest result from where it will retrieve information about how many events have taken place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0b9e5e8-f2ce-4a1f-b8e1-38d461b7a104",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_URL = 'REDACTED'\n",
    "URL = base_URL + '/results/latestresults/'\n",
    "headers = {'User-Agent': 'REDACTED'}\n",
    "page = requests.get(URL, headers=headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5392e81b-bf5f-485c-ac75-2ed83f9aeb9e",
   "metadata": {},
   "source": [
    "I use BeautifulSoup to parse the html content and extract the latest event number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eaa66a8a-e4ec-4b40-a686-91866ab419ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "res_header = soup.find('div', {'class': 'Results-header'})\n",
    "event_number = int(str(res_header.find(string=re.compile('#\\d+')))[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b7add549-3147-44cf-a737-5b945ac8a539",
   "metadata": {},
   "outputs": [],
   "source": [
    "events = [] # event number of the current event\n",
    "position = []\n",
    "name = []\n",
    "agegroup = []\n",
    "gender = []\n",
    "club = []\n",
    "times = []\n",
    "age_grade = [] # age graded ranking (percentage)\n",
    "runs = [] # number of runs completed of the runner\n",
    "volunteered = [] # number of times the runner has volunteered at a running event"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d1b46f-7a08-43ca-8584-c6bc62483d66",
   "metadata": {},
   "source": [
    "Next, I create a for loop that repeats the following steps for every run in the history event."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bbea75d4-6899-4624-a9b0-0e0a60928448",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the website of the event uses captcha to restrict access. accordingly, you have to adjust\n",
    "# the range for this for loop and run it multiple times.\n",
    "for event in range(event_number):\n",
    "    # scrape html content of the event result page\n",
    "    URL = base_URL + f'/results/{event+1}'\n",
    "    page = requests.get(URL, headers=headers)\n",
    "    \n",
    "    # make a list of all rows from the results table\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    table = soup.find('table', {'class':'Results-table'})\n",
    "    rows = table.find_all('tr', class_='Results-table-row')\n",
    "    \n",
    "    # iterate over each row and extract the information\n",
    "    for r in rows:\n",
    "        events.append(event+1)\n",
    "        \n",
    "        if re.search(r'data-name=\"[^0-9]+(?: [^0-9]+)*\\.?\"', str(r)) is not None:\n",
    "            name.append(re.search(r'data-name=\"[^0-9]+(?: [^0-9]+)*\\.?\"', str(r)).group(0))\n",
    "        else:\n",
    "            name.append('NaN')\n",
    "            \n",
    "        if re.search(r'data-position=\"\\d+\"', str(r)) is not None:\n",
    "            position.append(re.search(r'data-position=\"\\d+\"', str(r)).group(0))\n",
    "        else:\n",
    "            position.append('NaN')\n",
    "            \n",
    "        if re.search(r'data-gender=\"[^\"]*\"', str(r)) is not None:\n",
    "            gender.append(re.search(r'data-gender=\"[^\"]*\"', str(r)).group(0))\n",
    "        else:\n",
    "            gender.append('NaN')\n",
    "            \n",
    "        if re.search(r'data-club=\"[^\"]*\"', str(r)) is not None:\n",
    "            club.append(re.search(r'data-club=\"[^\"]*\"', str(r)).group(0))\n",
    "        else:\n",
    "            club.append('NaN')\n",
    "        \n",
    "        if re.search(r'data-vols=\"\\d+\"', str(r)) is not None:\n",
    "            volunteered.append(re.search(r'data-vols=\"\\d+\"', str(r)).group(0))\n",
    "        else:\n",
    "            volunteered.append('NaN')\n",
    "            \n",
    "        if re.search(r'data-runs=\"\\d+\"', str(r)) is not None:\n",
    "            runs.append(re.search(r'data-runs=\"\\d+\"', str(r)).group(0))\n",
    "        else:\n",
    "            runs.append('NaN')\n",
    "        \n",
    "        if re.search(r'data-agegrade=\"\\d+\\.\\d+\"', str(r)) is not None:\n",
    "            age_grade.append(re.search(r'data-agegrade=\"\\d+\\.\\d+\"', str(r)).group(0))\n",
    "        else:\n",
    "            age_grade.append('NaN')\n",
    "            \n",
    "        if re.search(r'data-agegroup=\"[A-Z]{2}\\d{2}(-\\d{2})?\"', str(r)) is not None:\n",
    "            agegroup.append(re.search(r'data-agegroup=\"[A-Z]{2}\\d{2}(-\\d{2})?\"', str(r)).group(0))\n",
    "        else:\n",
    "            agegroup.append('NaN')\n",
    "\n",
    "        if r.find(string=re.compile(r'(\\d:)?\\d{2}:\\d{2}')) is not None:\n",
    "            finish_time = r.find(string=re.compile(r'(\\d:)?\\d{2}:\\d{2}'))\n",
    "            times.append(finish_time)\n",
    "        else:\n",
    "            times.append('NaN')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "981520cd-9349-4d11-b986-c49328fd8032",
   "metadata": {},
   "source": [
    "Some of the lists still include more information than we want. This sequence filters everything that is between the quotation marks of the list items of these lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "387b553a-6a76-483d-a96b-808cc9faa4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lists = [agegroup, gender, club, age_grade, runs, volunteered, position]\n",
    "\n",
    "for l in lists:\n",
    "    for i, item in enumerate(l):\n",
    "        if re.search(r'[a-zA-Z\\-]=\"([^\"]*)\"', item) is not None:\n",
    "            l[i] = re.search(r'[a-zA-Z\\-]=\"([^\"]*)\"', item).group(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96fe8794-7d65-446a-85d2-6eda5c1e3225",
   "metadata": {},
   "source": [
    "Now I combine all lists to a data frame and anonymise the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ba655ef9-0caa-4484-b592-9c418c8e4df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {'event_nr': events,\n",
    "             'position': position,\n",
    "             'runner': name,\n",
    "             'agegroup': agegroup,\n",
    "             'gender': gender,\n",
    "             'club': club,\n",
    "             'time': times,\n",
    "             'age_grade': age_grade,\n",
    "             'no_runs': runs,\n",
    "             'no_volunteered': volunteered}\n",
    "\n",
    "data = pd.DataFrame(data_dict)\n",
    "\n",
    "data['runner'] = data['runner'].apply(lambda x: hashlib.sha256(x.encode()).hexdigest())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458a742d-c0b8-4167-b26b-fc0b7abad4ab",
   "metadata": {},
   "source": [
    "Finally, I save the dataframe to a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9370a0ee-51b2-4679-a2e9-b6750f04b2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('5k_KN_full_results.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
